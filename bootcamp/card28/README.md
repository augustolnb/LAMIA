# Classificador de Embalagens de Fio Dental (Cheia ou Vazia)

## üìñ Descri√ß√£o do Projeto

Este projeto apresenta uma solu√ß√£o de Vis√£o Computacional proposta como trabalho final do **bootcamp de machine learning**.

O modelo implementado realiza a classifica√ß√£o bin√°ria de embalagens de fio dental, determinando se elas est√£o **cheias** ou **vazias**. 

Uma aplica√ß√£o plaus√≠vel seria automatizar o processo de verifica√ß√£o de integridade do produto em uma linha de produ√ß√£o ou estoque, utilizando uma Rede Neural Convolucional (CNN) treinada para a tarefa.

O sistema foi desenvolvido em Python, utilizando a biblioteca TensorFlow/Keras para a constru√ß√£o e treinamento do modelo, no ambiente online do Google Colab.

`[Placeholder para imagem: GIF ou imagem demonstrando o sistema em a√ß√£o, classificando uma imagem de embalagem cheia e outra vazia.]`

## üõ†Ô∏è Funcionalidades

-   **Classifica√ß√£o Bin√°ria:** Distingue as embalagens entre cheias e vazias.
-   **Dataset Robusto:** Utiliza um dataset com mais de 4000 imagens capturadas manualmente em condi√ß√µes variadas.
-   **Pr√©-processamento Automatizado:** Inclui scripts para processar as imagens originais e prepar√°-las para o treinamento.
-   
## üìä O Dataset

A base de dados do projeto √© um dataset criado especificamente para este problema.

-   **Total de Imagens:** 4066
-   **Classes:** `Cheia` e `Vazia`
-   **Origem:** Fotos tiradas manualmente com um smartphone, garantindo uma variedade de √¢ngulos, ilumina√ß√µes e posicionamentos.

### Etapas de Pr√©-processamento

Para garantir que o modelo recebesse dados adequados, as imagens originais passaram por um *pipeline* de pr√©-processamento dividido em tr√™s etapas principais, utilizando os scripts localizados na pasta `misc/`.

**1. Organiza√ß√£o do Dataset (`misc/01-DS-new.py`)**

Este script foi o ponto de partida para a estrutura√ß√£o dos dados. Ele foi respons√°vel por organizar as imagens originais, separando-as em suas respectivas pastas de classe (`cheia`/`vazia`) 

**2. Sele√ß√£o da Regi√£o de Interesse (ROI) (`misc/02-selecionar_ROI.py`)**

As fotos originais continham muito ru√≠do de fundo. Para que o modelo focasse exclusivamente na embalagem, este script foi utilizado para cortar a Regi√£o de Interesse (ROI) de cada imagem.

`[Placeholder para imagem: Exemplo de imagem original vs. imagem com ROI selecionado lado a lado.]`

**3. Normaliza√ß√£o e Redimensionamento (`misc/03-NORMALIZE.py`)**

A etapa final de prepara√ß√£o. Este script processa as imagens cortadas para:
-   **Redimensionar:** Todas as imagens foram padronizadas para as dimens√µes exigidas pela entrada do modelo (128x128 pixels).
-   **Convers√£o da Escala de Cores:** As imagens foram todas convertidas para escala de cinza com o objetivo de otimizar e acelerar o processo de treinamento da rede neural.

`[Placeholder para imagem: Exemplo de imagem antes e depois da normaliza√ß√£o, mostrando a mudan√ßa de tamanho e talvez um filtro de cor, se aplicado.]`

## üß† O Modelo de IA

O cora√ß√£o deste projeto √© uma **Rede Neural Convolucional (CNN)**, uma arquitetura ideal para tarefas de classifica√ß√£o de imagens.

### Arquitetura

O modelo foi constru√≠do em Keras e possui a seguinte estrutura:

```python
# C√≥digo do modelo final extra√≠do do notebook card28.ipynb
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(128, 128, 1)),

    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    
    # Camada de Dropout para regulariza√ß√£o
    tf.keras.layers.Dropout(dropout_rate),
    
    # Camada de sa√≠da com 2 neur√¥nios (um para cada classe)
    tf.keras.layers.Dense(num_classes) 
])

optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

```

### Performance

Ap√≥s o treinamento com os hiperpar√¢metros inicialmente propostos foram feitos testes utilizando a t√©cnica de *Grid Search* para otimizar esses hiperpr√¢metros.
Por fim, os valores utilizados no modelo final foram:

- **Taxa de Aprendizagem (Learning Rate):** 1e-3
- **Taxa de Dropout:** 0.4
- **√âpocas de Treinamento:** 13
- **Tamanho do Lote (Batch Size):** 32

A matriz de confus√£o abaixo ilustra o desempenho detalhado do modelo:

`[Placeholder para a imagem da Matriz de Confus√£o gerada pelo notebook.]`

## üöÄ Como Usar

### Pr√©-requisitos

-   Python 3.8+
-   pip (Python Package Installer)
-   Git

### Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/seu-usuario/seu-repositorio.git
    cd seu-repositorio
    ```

2.  **Crie e ative um ambiente virtual (Recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

### Executando uma Previs√£o

Para classificar uma nova imagem, voc√™ pode usar o modelo treinado com um script como este:

```python
import tensorflow as tf
import numpy as np
import cv2

# Carregar o modelo treinado
# model = tf.keras.models.load_model('caminho/para/seu/modelo.h5')

# Fun√ß√£o de predi√ß√£o adaptada do notebook
def prever_nova_imagem(caminho_imagem, model):
    img = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"Erro: N√£o foi poss√≠vel carregar a imagem em {caminho_imagem}")
        return None, None

    img_resized = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)
    img_normalized = img_resized.astype("float32") / 255.0
    img_tensor = np.expand_dims(img_normalized, axis=-1)
    img_tensor = np.expand_dims(img_tensor, axis=0)

    predictions = model.predict(img_tensor)
    probabilities = tf.nn.softmax(predictions).numpy()[0]
    predicted_class_index = np.argmax(predictions, axis=1)
    
    class_names = ['empty', 'full']
    predicted_class = class_names[predicted_class_index[0]]
    
    return predicted_class, probabilities

# Exemplo de uso
# caminho_da_nova_imagem = 'caminho/para/sua/imagem.jpg'
# classe_predita, probabilidades = prever_nova_imagem(caminho_da_nova_imagem, model)

# if classe_predita:
#     print(f"A imagem √© provavelmente: {classe_predita}")
#     print(f"Probabilidade de ser 'empty': {probabilidades[0]:.2f}")
#     print(f"Probabilidade de ser 'full': {probabilidades[1]:.2f}")

```

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ misc/                # Scripts de suporte para cria√ß√£o e pr√©-processamento do dataset.
‚îÇ   ‚îú‚îÄ‚îÄ 01-DS-new.py
‚îÇ   ‚îú‚îÄ‚îÄ 02-selecionar_ROI.py
‚îÇ   ‚îî‚îÄ‚îÄ 03-NORMALIZE.py
‚îú‚îÄ‚îÄ card28.ipynb         # C√≥digo com o modelo 
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ dataset_dental_floss.zip
```

## ‚úíÔ∏è Autor

**Augusto** - `[Seu Sobrenome]`

-   **LinkedIn:** `[URL do seu LinkedIn]`
-   **GitHub:** `[URL do seu GitHub]`

