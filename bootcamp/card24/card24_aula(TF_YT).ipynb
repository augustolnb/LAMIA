{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "jqwcEhTiXKjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsAMqLzIQAGS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Eu amo meu doguinho\",\n",
        "    \"Eu amo pipoquinha\"\n",
        "]"
      ],
      "metadata": {
        "id": "RxES5HdzSXFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x1gwpcNSeXF",
        "outputId": "1092b809-7068-4007-82d8-5838fe6138de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eu': 1, 'amo': 2, 'meu': 3, 'doguinho': 4, 'pipoquinha': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequencing"
      ],
      "metadata": {
        "id": "b0PEBg2cXOVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDxuD-zOY7lQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Eu amo meu doguinho\",\n",
        "    \"Eu amo pipoquinha\",\n",
        "    \"Você gosta de jujuba\",\n",
        "    \"O mamão é uma das frutas mais nutritivas e populares do mundo e é consumido preferencialmente como fruta fresca.\"\n",
        "]"
      ],
      "metadata": {
        "id": "CWXFBAhdY7lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "print(word_index)\n",
        "print(\"\\n\")\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaa5f0b-94d5-4888-c9bb-83654cc9f37d",
        "id": "hwFMxSA7Y-fu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eu': 1, 'amo': 2, 'é': 3, 'e': 4, 'meu': 5, 'doguinho': 6, 'pipoquinha': 7, 'você': 8, 'gosta': 9, 'de': 10, 'jujuba': 11, 'o': 12, 'mamão': 13, 'uma': 14, 'das': 15, 'frutas': 16, 'mais': 17, 'nutritivas': 18, 'populares': 19, 'do': 20, 'mundo': 21, 'consumido': 22, 'preferencialmente': 23, 'como': 24, 'fruta': 25, 'fresca': 26}\n",
            "\n",
            "\n",
            "[[1, 2, 5, 6], [1, 2, 7], [8, 9, 10, 11], [12, 13, 3, 14, 15, 16, 17, 18, 4, 19, 20, 21, 4, 3, 22, 23, 24, 25, 26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### token oov"
      ],
      "metadata": {
        "id": "tBoMxkjGb2-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "test = [\n",
        "    \"O buriti é um fruto de alto valor nutricional\",\n",
        "    \"O barbatimão é conhecido por suas diversas propriedades medicinais\"\n",
        "]\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "print(test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138afef7-28f0-4c6a-f4e4-9da8b4e441c6",
        "id": "ZTZkOosLahu4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13, 1, 4, 1, 1, 11, 1, 1, 1], [13, 1, 4, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pad_sequences"
      ],
      "metadata": {
        "id": "RfLj-pxAb5xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "test = [\n",
        "    \"O buriti é um fruto conhecido por seu alto valor nutricional\",\n",
        "    \"O barbatimão é conhecido por suas propriedades medicinais\",\n",
        "    \"O jamelão é roxinho\"\n",
        "]\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "padded = pad_sequences(sequences, padding=\"post\")\n",
        "\n",
        "print(padded[0])\n",
        "print(padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOboW1hcZbLs",
        "outputId": "7ee158e4-e882-4b44-a645-e58b5e531029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13  1  4  1  1  1  1  1  1  1  1]\n",
            "(3, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### treinando um modelo"
      ],
      "metadata": {
        "id": "B0LtBKExqC-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense"
      ],
      "metadata": {
        "id": "FqtynJX_qPzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"O buriti é um fruto conhecido por seu alto valor nutricional\",\n",
        "    \"O barbatimão é conhecido por suas propriedades medicinais\",\n",
        "    \"O jamelão é roxinho\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0]  # Exemplo: 1 para \"nutricional/medicinal\", 0 para outroslabels = [0, 1, 0]  # Substitua pelos seus rótulos (ex.: 0 ou 1 para classificação binária)\n",
        "\n",
        "vocab_size = 100  # Tamanho máximo do vocabulário\n",
        "embedding_dim = 16  # Dimensão dos vetores de embedding\n",
        "max_length = 10    # Comprimento máximo das sequências\n",
        "padding_type = \"post\"  # Tipo de padding (pós ou pré)\n",
        "trunc_type = \"post\"    # Tipo de truncamento (pós ou pré)"
      ],
      "metadata": {
        "id": "8D4uZ0WZoZh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados em conjuntos de treinamento e teste\n",
        "training_size = 2  # Define o tamanho do conjunto de treinamento (2 frases)\n",
        "training_sentences = sentences[0:training_size]  # Seleciona as primeiras 'training_size' frases\n",
        "testing_sentences = sentences[training_size:]   # Seleciona as frases restantes para teste\n",
        "training_labels = labels[0:training_size]       # Seleciona os rótulos correspondentes ao treinamento\n",
        "testing_labels = labels[training_size:]         # Seleciona os rótulos correspondentes ao teste\n",
        "training_labels_np = np.array(training_labels)\n",
        "testing_labels_np = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "tyZn2XucqFp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do tokenizador\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"oov_tok\")  # Cria o tokenizador com tamanho de vocabulário e token OOV\n",
        "tokenizer.fit_on_texts(training_sentences)  # Constrói o vocabulário com base nas frases de treinamento\n",
        "word_index = tokenizer.word_index  # Armazena o mapeamento de palavras para índices\n",
        "\n",
        "\n",
        "# Conversão das frases em sequências numéricas\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)  # Converte frases de treinamento em sequências\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)  # Padroniza o comprimento das sequências\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)  # Converte frases de teste em sequências\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)  # Padroniza o comprimento das sequências"
      ],
      "metadata": {
        "id": "CzxzIZgQqj4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do modelo\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),  # Camada de embedding para representar palavras como vetores\n",
        "    GlobalAveragePooling1D(),  # Camada de pooling para reduzir a dimensionalidade\n",
        "    Dense(24, activation='relu'),  # Camada densa com ativação ReLU\n",
        "    Dense(1, activation='sigmoid')  # Camada de saída com ativação sigmoid para classificação binária\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Configura a função de perda, otimizador e métricas"
      ],
      "metadata": {
        "id": "kJswq20MqulZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo (assumindo que training_padded e training_labels estão prontos)\n",
        "history = model.fit(training_padded, training_labels_np, epochs=10, validation_data=(testing_padded, testing_labels_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRoWgXZIqyAB",
        "outputId": "6d014eea-cbfa-4e6a-d95c-9d3e963d1abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 0.6969 - val_accuracy: 0.0000e+00 - val_loss: 0.7006\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.5000 - loss: 0.6934 - val_accuracy: 0.0000e+00 - val_loss: 0.7042\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5000 - loss: 0.6902 - val_accuracy: 0.0000e+00 - val_loss: 0.7078\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.6868 - val_accuracy: 0.0000e+00 - val_loss: 0.7115\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.6832 - val_accuracy: 0.0000e+00 - val_loss: 0.7152\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.6796 - val_accuracy: 0.0000e+00 - val_loss: 0.7189\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.6762 - val_accuracy: 0.0000e+00 - val_loss: 0.7227\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.6730 - val_accuracy: 0.0000e+00 - val_loss: 0.7265\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.6697 - val_accuracy: 0.0000e+00 - val_loss: 0.7302\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.6663 - val_accuracy: 0.0000e+00 - val_loss: 0.7342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e136755e290>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(testing_padded, testing_labels_np)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKtzvWdNqy9I",
        "outputId": "9365e7fa-6571-4e74-eb9c-7e7faf04307b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.7342\n",
            "Loss: 0.734200119972229, Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ye56f8BFrTaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}